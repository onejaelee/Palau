{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1da334e8",
   "metadata": {},
   "source": [
    "# Download GHCNd Data\n",
    "\n",
    "This downloads the Global Historical Climatology Network daily (GHCNd). This downloads the required data for the 1.2 Surface Temperature indicators and 1.3 Rainfall indicators\n",
    "\n",
    "### Description from NOAA:\n",
    "\n",
    "The Global Historical Climatology Network daily (GHCNd) is an integrated database of daily climate summaries from land surface stations across the globe. GHCNd is made up of daily climate records from numerous sources that have been integrated and subjected to a common suite of quality assurance reviews.\n",
    "\n",
    "GHCNd contains records from more than 100,000 stations in 180 countries and territories. NCEI provides numerous daily variables, including maximum and minimum temperature, total daily precipitation, snowfall, and snow depth. About half the stations only report precipitation. Both record length and period of record vary by station and cover intervals ranging from less than a year to more than 175 years.\n",
    "\n",
    "\n",
    "Further information can be found at https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de1d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba679575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68faf977",
   "metadata": {},
   "outputs": [],
   "source": [
    "GHCND_dir = \"https://www.ncei.noaa.gov/data/global-historical-climatology-network-daily/access/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac0f2909",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_folder = './GHCNd/'\n",
    "if not os.path.exists(download_folder):\n",
    "    os.makedirs(download_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7a452c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(GHCND_dir, headers={'User-Agent': 'Chrome'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9629412",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd8fdb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleantext = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfe7531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_date = cleantext.find_all([\"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "963996e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GHCND_files = []\n",
    "\n",
    "for x in BeautifulSoup(r.text).find_all(['a'])[5:]:\n",
    "    GHCND_files.append(re.findall(r'\"([^\"]*)\"', str(x))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2ca695d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSC00914015.csv\n",
      "PSC00914030.csv\n",
      "PSC00914465.csv\n",
      "PSC00914478.csv\n",
      "PSC00914519.csv\n",
      "PSC00914580.csv\n",
      "PSC00914712.csv\n",
      "PSC00914840.csv\n",
      "PSC00914913.csv\n",
      "PSW00040305.csv\n",
      "PSW00040307.csv\n",
      "PSW00040309.csv\n"
     ]
    }
   ],
   "source": [
    "for palau_file in [x for x in GHCND_files if x[:2] == \"PS\"]:\n",
    "    print(palau_file)\n",
    "    urllib.request.urlretrieve(GHCND_dir + palau_file, download_folder + palau_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "784f7af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d6/w300s4cx3qj10pqdcy5859bc0000gn/T/ipykernel_64245/1959920488.py:3: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  print(pd.read_csv(download_folder+x)['NAME'].unique()[0], len(pd.read_csv(download_folder+x)['NAME'].unique()))\n",
      "/var/folders/d6/w300s4cx3qj10pqdcy5859bc0000gn/T/ipykernel_64245/1959920488.py:3: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  print(pd.read_csv(download_folder+x)['NAME'].unique()[0], len(pd.read_csv(download_folder+x)['NAME'].unique()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KOROR, PW PS 1\n",
      "MALAKAL RES, PW PS 1\n",
      "TOBI, UM US 1\n",
      "PELELIU, PW PS 1\n",
      "AIMELIK BABELTHUAP, PW PS 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d6/w300s4cx3qj10pqdcy5859bc0000gn/T/ipykernel_64245/1959920488.py:4: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  palau_dict[x] = pd.read_csv(download_folder+x)['NAME'].unique()[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANGUAR, PW PS 1\n",
      "NGASANG BABELTHUAP, PW PS 1\n",
      "WEATHER SERVICE OFFICE PALAU, PW PS 1\n",
      "MARICULTURE CENTER, PW PS 1\n",
      "NEKKEN FORESTRY, PW PS 1\n",
      "PELELIU ISLAND PALAU ISLANDS, PW PS 1\n",
      "KOROR ISLAND NF, PW PS 1\n"
     ]
    }
   ],
   "source": [
    "palau_dict = {}\n",
    "for x in os.listdir(download_folder):\n",
    "    print(pd.read_csv(download_folder+x)['NAME'].unique()[0], len(pd.read_csv(download_folder+x)['NAME'].unique()))\n",
    "    palau_dict[x] = pd.read_csv(download_folder+x)['NAME'].unique()[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cff8576f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PSW00040309.csv': 'KOROR, PW PS',\n",
       " 'PSC00914465.csv': 'MALAKAL RES, PW PS',\n",
       " 'PSC00914840.csv': 'TOBI, UM US',\n",
       " 'PSC00914712.csv': 'PELELIU, PW PS',\n",
       " 'PSC00914015.csv': 'AIMELIK BABELTHUAP, PW PS',\n",
       " 'PSC00914030.csv': 'ANGUAR, PW PS',\n",
       " 'PSC00914580.csv': 'NGASANG BABELTHUAP, PW PS',\n",
       " 'PSC00914913.csv': 'WEATHER SERVICE OFFICE PALAU, PW PS',\n",
       " 'PSC00914478.csv': 'MARICULTURE CENTER, PW PS',\n",
       " 'PSC00914519.csv': 'NEKKEN FORESTRY, PW PS',\n",
       " 'PSW00040305.csv': 'PELELIU ISLAND PALAU ISLANDS, PW PS',\n",
       " 'PSW00040307.csv': 'KOROR ISLAND NF, PW PS'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palau_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce26398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = ['TMAX','TMIN',\"TOBS\",\n",
    " \"DAPR\",\"MDPR\",\"PRCP\",\"SNOW\",\"SNWD\",\n",
    " \"ACMH\",\"ACSH\",\"PSUN\",\"TSUN\",\"WESD\",\n",
    " \"WT01\",\"WT03\",\"WT05\",\"WT07\",\"WT08\",\"WT11\",\"WT14\",\"WT16\",\"WT18\",\"WT20\",\n",
    "\"AWND\",\"FMTM\",\"PGTM\",\"WDF1\",\"WDF2\",\"WDF5\",\"WDFG\",\"WDFM\",\"WSF1\",\"WSF2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c92a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "airtemp_list = ['TMAX','TMIN',\"TOBS\"]\n",
    "precip_list = [\"DAPR\",\"MDPR\",\"PRCP\",\"SNOW\",\"SNWD\"]\n",
    "sky_list = [\"ACMH\",\"ACSH\"]\n",
    "sun_list = [\"PSUN\",\"TSUN\"]\n",
    "water_list = [\"WESD\"]\n",
    "weathertype_list = [\"WT01\",\"WT03\",\"WT05\",\"WT07\",\"WT08\",\"WT11\",\"WT14\",\"WT16\",\"WT18\",\"WT20\"]\n",
    "wind_list = [\"AWND\",\"FMTM\",\"PGTM\",\"WDF1\",\"WDF2\",\"WDF5\",\"WDFG\",\"WDFM\",\"WSF1\",\"WSF2\"]\n",
    "type_list = [airtemp_list,precip_list,sky_list,sun_list,water_list,weathertype_list,wind_list]\n",
    "var_names = [\"AIRTEMP\",\"PRECIP\",\"SKY\",\"SUN\",\"WATER\",\"WEATHERTYPE\",\"WIND\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8c9ab66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d6/w300s4cx3qj10pqdcy5859bc0000gn/T/ipykernel_64245/417439165.py:2: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  curr_df = pd.read_csv(download_folder+x)\n"
     ]
    }
   ],
   "source": [
    "for x in os.listdir(download_folder):\n",
    "    curr_df = pd.read_csv(download_folder+x)\n",
    "    palau_dict[x] = [palau_dict[x]] + [x for x in var_list if x in curr_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c5e6e715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d6/w300s4cx3qj10pqdcy5859bc0000gn/T/ipykernel_64245/1816627755.py:2: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  curr_df = pd.read_csv(download_folder+x)\n"
     ]
    }
   ],
   "source": [
    "for x in os.listdir(download_folder):\n",
    "    curr_df = pd.read_csv(download_folder+x)\n",
    "    df_cleaned = curr_df.dropna(axis=1, how='all')\n",
    "#     print(x)\n",
    "#     print(len(df_cleaned.columns) == len(curr_df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fe6a86f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_variables = [\"NAME\", \"STATION\" ,\"DATE\",\"LATITUDE\", \"LONGITUDE\", \"ELEVATION\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "96524fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_folder = './GHCND/pkl/'\n",
    "if not os.path.exists(pkl_folder):\n",
    "    os.makedirs(pkl_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "2694b019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIRTEMP_KOROR_PSW00040309\n",
      "AIRTEMP_AIMELIK_BABELTHUAP_PSC00914015\n",
      "AIRTEMP_ANGUAR_PSC00914030\n",
      "AIRTEMP_NGASANG_BABELTHUAP_PSC00914580\n",
      "AIRTEMP_NEKKEN_FORESTRY_PSC00914519\n",
      "PRECIP_PELELIU_PSC00914712\n",
      "PRECIP_AIMELIK_BABELTHUAP_PSC00914015\n",
      "PRECIP_ANGUAR_PSC00914030\n",
      "PRECIP_NGASANG_BABELTHUAP_PSC00914580\n",
      "PRECIP_MARICULTURE_CENTER_PSC00914478\n",
      "PRECIP_NEKKEN_FORESTRY_PSC00914519\n",
      "SKY_KOROR_PSW00040309\n",
      "SUN_KOROR_PSW00040309\n",
      "WATER_KOROR_PSW00040309\n",
      "WIND_KOROR_PSW00040309\n"
     ]
    }
   ],
   "source": [
    "#prints station-variable combinations with comprehensive variables for each category\n",
    "for l in range(len(type_list)):\n",
    "    df_list = []\n",
    "    for x in os.listdir(download_folder):\n",
    "        curr_df = pd.read_csv(download_folder+x,low_memory=False)\n",
    "        if all(elem in curr_df.columns for elem in type_list[l]):\n",
    "            station_name = curr_df[base_variables+type_list[l]]['NAME'][0][:curr_df[base_variables+type_list[l]]['NAME'][0].find(',')].replace(' ','_')\n",
    "            station_code = curr_df[base_variables+type_list[l]]['STATION'][0]\n",
    "            df_list.append(curr_df[base_variables+type_list[l]])\n",
    "            print(var_names[l] + \"_\" + station_name + \"_\" + station_code )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "128bf98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIRTEMP_KOROR_PSW00040309.pkl\n",
      "AIRTEMP_PELELIU_PSC00914712.pkl\n",
      "AIRTEMP_AIMELIK_BABELTHUAP_PSC00914015.pkl\n",
      "AIRTEMP_ANGUAR_PSC00914030.pkl\n",
      "AIRTEMP_NGASANG_BABELTHUAP_PSC00914580.pkl\n",
      "AIRTEMP_WEATHER_SERVICE_OFFICE_PALAU_PSC00914913.pkl\n",
      "AIRTEMP_MARICULTURE_CENTER_PSC00914478.pkl\n",
      "AIRTEMP_NEKKEN_FORESTRY_PSC00914519.pkl\n",
      "AIRTEMP_PELELIU_ISLAND_PALAU_ISLANDS_PSW00040305.pkl\n",
      "AIRTEMP_KOROR_ISLAND_NF_PSW00040307.pkl\n",
      "AIRTEMP_PALAU.pkl\n",
      "PRECIP_KOROR_PSW00040309.pkl\n",
      "PRECIP_MALAKAL_RES_PSC00914465.pkl\n",
      "PRECIP_TOBI_PSC00914840.pkl\n",
      "PRECIP_PELELIU_PSC00914712.pkl\n",
      "PRECIP_AIMELIK_BABELTHUAP_PSC00914015.pkl\n",
      "PRECIP_ANGUAR_PSC00914030.pkl\n",
      "PRECIP_NGASANG_BABELTHUAP_PSC00914580.pkl\n",
      "PRECIP_WEATHER_SERVICE_OFFICE_PALAU_PSC00914913.pkl\n",
      "PRECIP_MARICULTURE_CENTER_PSC00914478.pkl\n",
      "PRECIP_NEKKEN_FORESTRY_PSC00914519.pkl\n",
      "PRECIP_PELELIU_ISLAND_PALAU_ISLANDS_PSW00040305.pkl\n",
      "PRECIP_KOROR_ISLAND_NF_PSW00040307.pkl\n",
      "PRECIP_PALAU.pkl\n",
      "SKY_KOROR_PSW00040309.pkl\n",
      "SKY_PALAU.pkl\n",
      "SUN_KOROR_PSW00040309.pkl\n",
      "SUN_PALAU.pkl\n",
      "WATER_KOROR_PSW00040309.pkl\n",
      "WATER_PALAU.pkl\n",
      "WEATHERTYPE_KOROR_PSW00040309.pkl\n",
      "WEATHERTYPE_AIMELIK_BABELTHUAP_PSC00914015.pkl\n",
      "WEATHERTYPE_ANGUAR_PSC00914030.pkl\n",
      "WEATHERTYPE_NGASANG_BABELTHUAP_PSC00914580.pkl\n",
      "WEATHERTYPE_MARICULTURE_CENTER_PSC00914478.pkl\n",
      "WEATHERTYPE_NEKKEN_FORESTRY_PSC00914519.pkl\n",
      "WEATHERTYPE_PELELIU_ISLAND_PALAU_ISLANDS_PSW00040305.pkl\n",
      "WEATHERTYPE_KOROR_ISLAND_NF_PSW00040307.pkl\n",
      "WEATHERTYPE_PALAU.pkl\n",
      "WIND_KOROR_PSW00040309.pkl\n",
      "WIND_PALAU.pkl\n"
     ]
    }
   ],
   "source": [
    "#prints station-variable combinations with any amount of variable(s) for each category\n",
    "\n",
    "for l in range(len(type_list)):\n",
    "    df_list = []\n",
    "    for x in os.listdir(download_folder):\n",
    "        if x[-3:]!= \"csv\":\n",
    "            continue\n",
    "        curr_df = pd.read_csv(download_folder+x,low_memory=False)\n",
    "        if any(elem in curr_df.columns for elem in type_list[l]):\n",
    "            filled_var = [x for x in curr_df.columns if x in type_list[l] or x in base_variables]\n",
    "            station_name = curr_df[filled_var]['NAME'][0][:curr_df[filled_var]['NAME'][0].find(',')].replace(' ','_')\n",
    "            station_code = curr_df[filled_var]['STATION'][0]\n",
    "            df_list.append(curr_df[filled_var].dropna(thresh=7).reset_index(drop=True))\n",
    "            file_name = var_names[l] + \"_\" + station_name + \"_\" + station_code+ \".pkl\"\n",
    "            print(file_name)\n",
    "            curr_df[filled_var].dropna(thresh=7).reset_index(drop=True).to_pickle(pkl_folder+file_name)\n",
    "\n",
    "    var_file_name = var_names[l] + \"_PALAU.pkl\"\n",
    "    \n",
    "    pd.concat(df_list).reset_index(drop=True).to_pickle(pkl_folder+var_file_name)\n",
    "    print(var_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
